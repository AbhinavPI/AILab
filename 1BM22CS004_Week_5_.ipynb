{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjmD6lVw/KKv9Ti2QQ2BkA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbhinavPI/AILab/blob/main/1BM22CS004_Week_5_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHrWoZLCsVZI"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "def count_attacks(queen_positions):\n",
        "    attack_count = 0\n",
        "    size = len(queen_positions)\n",
        "    for i in range(size):\n",
        "        for j in range(i + 1, size):\n",
        "            if queen_positions[i] == queen_positions[j]:\n",
        "                attack_count += 1\n",
        "            if abs(queen_positions[i] - queen_positions[j]) == abs(i - j):\n",
        "                attack_count += 1\n",
        "    return attack_count\n",
        "\n",
        "def generate_random_move(current_positions):\n",
        "    new_state = current_positions[:]\n",
        "    column_to_change = random.randint(0, len(current_positions) - 1)\n",
        "    new_row_position = random.randint(0, len(current_positions) - 1)\n",
        "    new_state[column_to_change] = new_row_position\n",
        "    return new_state\n",
        "\n",
        "def annealing_search(board_size, initial_configuration):\n",
        "    current_positions = initial_configuration[:]\n",
        "    current_attack_count = count_attacks(current_positions)\n",
        "    temp = 1000\n",
        "    min_temp = 0.0001\n",
        "    cooling_factor = 0.99\n",
        "    step_count = 0\n",
        "    visited_states = set()\n",
        "    while temp > min_temp and current_attack_count > 0:\n",
        "        step_count += 1\n",
        "        new_positions = generate_random_move(current_positions)\n",
        "        new_positions_tuple = tuple(new_positions)\n",
        "        if new_positions_tuple in visited_states:\n",
        "            continue\n",
        "        visited_states.add(new_positions_tuple)\n",
        "        new_attack_count = count_attacks(new_positions)\n",
        "        energy_difference = new_attack_count - current_attack_count\n",
        "        if energy_difference < 0 or random.random() < math.exp(-energy_difference / temp):\n",
        "            current_positions, current_attack_count = new_positions, new_attack_count\n",
        "        temp *= cooling_factor\n",
        "        if current_attack_count == 0:\n",
        "            print(\"Solution found after\", step_count, \"steps!\")\n",
        "            break\n",
        "    return current_positions, current_attack_count\n",
        "\n",
        "board_size = int(input(\"Enter the size of the board (N): \"))\n",
        "initial_input = input(\"Enter the initial configuration: \")\n",
        "initial_queen_positions = [int(pos) for pos in initial_input.strip('[]').split(',')]\n",
        "if len(initial_queen_positions) != board_size:\n",
        "    print(\"Error: The initial configuration must contain exactly\", board_size, \"integers.\")\n",
        "else:\n",
        "    solution, conflicts = annealing_search(board_size, initial_queen_positions)\n",
        "    if conflicts == 0:\n",
        "        print(\"Solution found!\")\n",
        "        print(\"Final board configuration:\", solution)\n",
        "    else:\n",
        "        print(\"No solution found. Final conflict count:\", conflicts)\n"
      ]
    }
  ]
}